#!/usr/bin/env python3
"""
æ•°æ®åŠ è½½ç»„ä»¶
æä¾›COCOæ•°æ®é›†åŠ è½½åŠŸèƒ½ï¼Œå‚è€ƒultimate_sanity_check.pyçš„éªŒè¯å®ç°
"""

import os
import sys
import json
import numpy as np
from PIL import Image

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/kyc/project/RT-DETR')

import jittor as jt

# COCOç±»åˆ«åç§°æ˜ å°„
COCO_CLASSES = {
    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',
    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',
    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',
    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',
    21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe',
    27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',
    34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite',
    39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard',
    43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup',
    48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana',
    53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot',
    58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair',
    63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table',
    70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote',
    76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',
    80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',
    89: 'hair drier', 90: 'toothbrush'
}

class COCODataset:
    """
    COCOæ•°æ®é›†åŠ è½½å™¨
    å‚è€ƒultimate_sanity_check.pyçš„éªŒè¯å®ç°
    """
    def __init__(self, img_dir, ann_file, augment_factor=1):
        self.img_dir = img_dir
        self.augment_factor = augment_factor
        
        # åŠ è½½COCOæ ‡æ³¨
        with open(ann_file, 'r') as f:
            self.coco_data = json.load(f)
        
        # åˆ›å»ºæ˜ å°„
        self.img_id_to_filename = {img['id']: img['file_name'] for img in self.coco_data['images']}
        self.img_ids = list(self.img_id_to_filename.keys())
        
        # æ•°æ®å¢å¼ºï¼šé‡å¤æ•°æ®
        if augment_factor > 1:
            self.img_ids = self.img_ids * augment_factor
        
        print(f"ğŸ“Š æ•°æ®é›†åŠ è½½å®Œæˆ:")
        print(f"   åŸå§‹å›¾åƒæ•°: {len(self.img_id_to_filename)}")
        print(f"   å¢å¼ºåæ•°æ®: {len(self.img_ids)}")
        print(f"   æ ‡æ³¨æ•°é‡: {len(self.coco_data['annotations'])}")

    def __len__(self):
        return len(self.img_ids)

    def __getitem__(self, idx):
        img_id = self.img_ids[idx]
        filename = self.img_id_to_filename[img_id]
        
        # åŠ è½½å›¾åƒ
        img_path = os.path.join(self.img_dir, filename)
        image = Image.open(img_path).convert('RGB')
        original_width, original_height = image.size
        
        # æ•°æ®å¢å¼ºï¼ˆç®€å•çš„éšæœºç¿»è½¬ï¼‰
        if self.augment_factor > 1 and np.random.random() > 0.5:
            image = image.transpose(Image.FLIP_LEFT_RIGHT)
        
        # è°ƒæ•´å›¾åƒå¤§å°åˆ°640x640
        image_resized = image.resize((640, 640), Image.LANCZOS)
        img_array = np.array(image_resized).astype(np.float32) / 255.0
        img_tensor = jt.array(img_array.transpose(2, 0, 1)).float32()
        
        # è·å–æ ‡æ³¨ - ä½¿ç”¨éªŒè¯è¿‡çš„ç±»åˆ«æ˜ å°„
        annotations = []
        labels = []
        
        for ann in self.coco_data['annotations']:
            if ann['image_id'] == img_id:
                x, y, w, h = ann['bbox']
                category_id = ann['category_id']
                
                # å½’ä¸€åŒ–åæ ‡
                x1, y1 = x / original_width, y / original_height
                x2, y2 = (x + w) / original_width, (y + h) / original_height
                
                if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0 and x2 <= 1 and y2 <= 1:
                    annotations.append([x1, y1, x2, y2])
                    
                    # ä½¿ç”¨éªŒè¯è¿‡çš„ç±»åˆ«æ˜ å°„
                    mapped_label = self._map_category_id(category_id)
                    labels.append(mapped_label)
        
        # åˆ›å»ºç›®æ ‡
        if annotations:
            target = {
                'boxes': jt.array(annotations, dtype=jt.float32),
                'labels': jt.array(labels, dtype=jt.int64)
            }
        else:
            target = {
                'boxes': jt.zeros((0, 4), dtype=jt.float32),
                'labels': jt.zeros((0,), dtype=jt.int64)
            }
        
        return img_tensor, target
    
    def _map_category_id(self, category_id):
        """
        COCOç±»åˆ«IDæ˜ å°„
        å‚è€ƒultimate_sanity_check.pyçš„å®ç°
        """
        if category_id == 1:  # person
            return 0
        elif category_id == 3:  # car
            return 2
        elif category_id == 27:  # backpack
            return 26
        elif category_id == 33:  # suitcase
            return 32
        elif category_id == 84:  # book
            return 83
        else:
            return category_id - 1
    
    def get_dataset_stats(self):
        """è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        category_counts = {}
        for ann in self.coco_data['annotations']:
            cat_id = ann['category_id']
            category_counts[cat_id] = category_counts.get(cat_id, 0) + 1
        
        # ç»Ÿè®¡è¾¹ç•Œæ¡†å¤§å°
        bbox_areas = []
        for ann in self.coco_data['annotations']:
            x, y, w, h = ann['bbox']
            area = w * h
            bbox_areas.append(area)
        
        bbox_areas = np.array(bbox_areas)
        
        return {
            'total_images': len(self.img_id_to_filename),
            'total_annotations': len(self.coco_data['annotations']),
            'category_counts': category_counts,
            'bbox_stats': {
                'mean_area': bbox_areas.mean(),
                'min_area': bbox_areas.min(),
                'max_area': bbox_areas.max(),
                'std_area': bbox_areas.std()
            }
        }
    
    def print_dataset_info(self):
        """æ‰“å°æ•°æ®é›†ä¿¡æ¯"""
        stats = self.get_dataset_stats()
        
        print("ğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   å›¾åƒæ•°é‡: {stats['total_images']}")
        print(f"   æ ‡æ³¨æ•°é‡: {stats['total_annotations']}")
        print(f"   å¹³å‡æ¯å¼ å›¾åƒæ ‡æ³¨æ•°: {stats['total_annotations']/stats['total_images']:.1f}")
        
        print(f"\nğŸ“¦ è¾¹ç•Œæ¡†ç»Ÿè®¡:")
        bbox_stats = stats['bbox_stats']
        print(f"   å¹³å‡é¢ç§¯: {bbox_stats['mean_area']:.2f}")
        print(f"   æœ€å°é¢ç§¯: {bbox_stats['min_area']:.2f}")
        print(f"   æœ€å¤§é¢ç§¯: {bbox_stats['max_area']:.2f}")
        
        print(f"\nğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ (å‰10ä¸ª):")
        sorted_cats = sorted(stats['category_counts'].items(), key=lambda x: x[1], reverse=True)[:10]
        for cat_id, count in sorted_cats:
            cat_name = COCO_CLASSES.get(cat_id, f"unknown_{cat_id}")
            print(f"   {cat_name} (ID:{cat_id}): {count}ä¸ªæ ‡æ³¨")

def create_coco_dataset(data_root, split='train', augment_factor=1):
    """
    åˆ›å»ºCOCOæ•°æ®é›†çš„å·¥å‚å‡½æ•°
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
        split: æ•°æ®é›†åˆ†å‰² ('train' æˆ– 'val')
        augment_factor: æ•°æ®å¢å¼ºå€æ•°
    
    Returns:
        dataset: COCOæ•°æ®é›†
    """
    if split == 'train':
        img_dir = os.path.join(data_root, 'train2017')
        ann_file = os.path.join(data_root, 'annotations', 'instances_train2017.json')
    elif split == 'val':
        img_dir = os.path.join(data_root, 'val2017')
        ann_file = os.path.join(data_root, 'annotations', 'instances_val2017.json')
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†åˆ†å‰²: {split}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(img_dir):
        raise FileNotFoundError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {img_dir}")
    if not os.path.exists(ann_file):
        raise FileNotFoundError(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ann_file}")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = COCODataset(img_dir, ann_file, augment_factor=augment_factor)
    dataset.print_dataset_info()
    
    return dataset

if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®é›†åŠ è½½
    print("ğŸ§ª æµ‹è¯•COCOæ•°æ®é›†ç»„ä»¶")
    print("=" * 50)
    
    data_root = "/home/kyc/project/RT-DETR/data/coco2017_50"
    
    try:
        # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
        train_dataset = create_coco_dataset(data_root, split='train', augment_factor=2)
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        img_tensor, target = train_dataset[0]
        print(f"\nâœ… æ•°æ®åŠ è½½æµ‹è¯•æˆåŠŸ!")
        print(f"   å›¾åƒå½¢çŠ¶: {img_tensor.shape}")
        print(f"   è¾¹ç•Œæ¡†æ•°é‡: {len(target['boxes'])}")
        print(f"   æ ‡ç­¾æ•°é‡: {len(target['labels'])}")
        
        print(f"\nğŸ‰ COCOæ•°æ®é›†ç»„ä»¶éªŒè¯å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
