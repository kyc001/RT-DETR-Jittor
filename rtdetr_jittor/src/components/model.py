#!/usr/bin/env python3
"""
RT-DETRæ¨¡å‹ç»„ä»¶
æä¾›å°è£…çš„RT-DETRæ¨¡å‹ï¼Œå‚è€ƒultimate_sanity_check.pyçš„éªŒè¯å®ç°
"""

import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/kyc/project/RT-DETR')

import jittor as jt
import jittor.nn as nn

# å¯¼å…¥éªŒè¯è¿‡çš„ç»„ä»¶
from ..nn.backbone.resnet import ResNet50
from ..zoo.rtdetr.rtdetr_decoder import RTDETRTransformer
from ..nn.criterion.rtdetr_criterion import build_criterion

class RTDETRModel(nn.Module):
    """
    å°è£…çš„RT-DETRæ¨¡å‹
    åŸºäºultimate_sanity_check.pyçš„éªŒè¯å®ç°
    """
    def __init__(self, num_classes=80, pretrained=True):
        super().__init__()
        
        # ä½¿ç”¨éªŒè¯è¿‡çš„backbone
        self.backbone = ResNet50(pretrained=pretrained)
        
        # ä½¿ç”¨éªŒè¯è¿‡çš„transformer
        self.transformer = RTDETRTransformer(
            num_classes=num_classes,
            hidden_dim=256,
            num_queries=300,
            feat_channels=[256, 512, 1024, 2048]
        )
        
        self.num_classes = num_classes
        
        if pretrained:
            print("âœ… ä½¿ç”¨Jittorå†…ç½®é¢„è®­ç»ƒæƒé‡")
        else:
            print("âš ï¸ ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
    
    def execute(self, x, targets=None):
        """
        å‰å‘ä¼ æ’­
        ç¡®ä¿è¿”å›å®Œæ•´çš„è¾“å‡ºåŒ…æ‹¬ç¼–ç å™¨è¾“å‡º
        """
        # ä½¿ç”¨éªŒè¯è¿‡çš„å‰å‘ä¼ æ’­æ–¹æ³•
        features = self.backbone(x)
        outputs = self.transformer(features, targets)
        
        # RTDETRTransformerå·²ç»åœ¨å…¶executeæ–¹æ³•ä¸­åŒ…å«äº†å®Œæ•´çš„è¾“å‡º
        # åŒ…æ‹¬pred_logits, pred_boxes, enc_outputsç­‰
        return outputs
    
    def get_criterion(self):
        """è·å–éªŒè¯è¿‡çš„æŸå¤±å‡½æ•°"""
        return build_criterion(num_classes=self.num_classes)
    
    def fix_batchnorm(self):
        """
        ä¿®å¤BatchNormé—®é¢˜
        å‚è€ƒultimate_sanity_check.pyçš„å®ç°
        """
        def _fix_batchnorm(module):
            for m in module.modules():
                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):
                    m.train()
                    # ç¡®ä¿BatchNormå‚æ•°å¯è®­ç»ƒ
                    if hasattr(m, 'weight') and m.weight is not None:
                        m.weight.requires_grad = True
                    if hasattr(m, 'bias') and m.bias is not None:
                        m.bias.requires_grad = True
        
        _fix_batchnorm(self)
    
    def get_trainable_params(self):
        """
        è·å–æ‰€æœ‰å¯è®­ç»ƒå‚æ•°
        å‚è€ƒultimate_sanity_check.pyçš„å®ç°
        """
        all_params = []
        for param in self.parameters():
            if param.requires_grad:
                all_params.append(param)
        return all_params
    
    def get_param_stats(self):
        """è·å–å‚æ•°ç»Ÿè®¡ä¿¡æ¯"""
        backbone_params = sum(p.numel() for p in self.backbone.parameters())
        transformer_params = sum(p.numel() for p in self.transformer.parameters())
        total_params = backbone_params + transformer_params
        trainable_params = len(self.get_trainable_params())
        
        return {
            'backbone_params': backbone_params,
            'transformer_params': transformer_params,
            'total_params': total_params,
            'trainable_params': trainable_params
        }
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        stats = self.get_param_stats()
        print("ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
        print(f"   Backboneå‚æ•°: {stats['backbone_params']:,}")
        print(f"   Transformerå‚æ•°: {stats['transformer_params']:,}")
        print(f"   æ€»å‚æ•°: {stats['total_params']:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°æ•°é‡: {stats['trainable_params']}")

def create_rtdetr_model(num_classes=80, pretrained=True):
    """
    åˆ›å»ºRT-DETRæ¨¡å‹çš„å·¥å‚å‡½æ•°
    
    Args:
        num_classes: ç±»åˆ«æ•°é‡
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
    
    Returns:
        model: RT-DETRæ¨¡å‹
        criterion: æŸå¤±å‡½æ•°
    """
    # è®¾ç½®Jittor
    jt.flags.use_cuda = 1
    jt.set_global_seed(42)
    jt.flags.auto_mixed_precision_level = 0
    
    # åˆ›å»ºæ¨¡å‹
    model = RTDETRModel(num_classes=num_classes, pretrained=pretrained)
    
    # ä¿®å¤BatchNorm
    model.fix_batchnorm()
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    criterion = model.get_criterion()
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    model.print_model_info()
    
    return model, criterion

def create_optimizer(model, lr=1e-4, weight_decay=0):
    """
    åˆ›å»ºä¼˜åŒ–å™¨
    å‚è€ƒultimate_sanity_check.pyçš„è®¾ç½®
    
    Args:
        model: RT-DETRæ¨¡å‹
        lr: å­¦ä¹ ç‡
        weight_decay: æƒé‡è¡°å‡
    
    Returns:
        optimizer: Jittorä¼˜åŒ–å™¨
    """
    trainable_params = model.get_trainable_params()
    optimizer = jt.optim.Adam(trainable_params, lr=lr, weight_decay=weight_decay)
    
    print(f"ğŸ“Š ä¼˜åŒ–å™¨é…ç½®:")
    print(f"   å­¦ä¹ ç‡: {lr}")
    print(f"   æƒé‡è¡°å‡: {weight_decay}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {len(trainable_params)}")
    
    return optimizer

if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("ğŸ§ª æµ‹è¯•RT-DETRæ¨¡å‹ç»„ä»¶")
    print("=" * 50)
    
    model, criterion = create_rtdetr_model(num_classes=80, pretrained=True)
    optimizer = create_optimizer(model, lr=1e-4)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    test_input = jt.randn(1, 3, 640, 640)
    with jt.no_grad():
        outputs = model(test_input)
    
    print(f"\nâœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ!")
    print(f"   è¾“å‡ºé”®: {list(outputs.keys())}")
    for key, value in outputs.items():
        print(f"   {key}: {value.shape}")
    
    print(f"\nğŸ‰ RT-DETRæ¨¡å‹ç»„ä»¶éªŒè¯å®Œæˆ!")
