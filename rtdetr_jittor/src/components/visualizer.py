#!/usr/bin/env python3
"""
å¯è§†åŒ–ç»„ä»¶
æä¾›RT-DETRæ¨ç†å’Œå¯è§†åŒ–åŠŸèƒ½ï¼Œå‚è€ƒultimate_sanity_check.pyçš„éªŒè¯å®ç°
"""

import os
import sys
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib
from scipy.special import softmax

# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/home/kyc/project/RT-DETR')

import jittor as jt

# COCOç±»åˆ«åç§°æ˜ å°„
COCO_CLASSES = {
    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',
    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',
    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',
    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep',
    21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe',
    27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase',
    34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite',
    39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard',
    43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup',
    48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana',
    53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot',
    58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair',
    63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table',
    70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote',
    76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',
    80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book',
    85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',
    89: 'hair drier', 90: 'toothbrush'
}

class RTDETRVisualizer:
    """
    RT-DETRå¯è§†åŒ–å™¨
    å‚è€ƒultimate_sanity_check.pyçš„éªŒè¯å®ç°
    """
    def __init__(self, model, conf_threshold=0.3, save_dir="./results/visualizations"):
        self.model = model
        self.conf_threshold = conf_threshold
        self.save_dir = save_dir
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"ğŸ“ å¯è§†åŒ–ç»“æœå°†ä¿å­˜åˆ°: {save_dir}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    
    def preprocess_image(self, image_path):
        """
        é¢„å¤„ç†å›¾åƒ
        å‚è€ƒultimate_sanity_check.pyçš„å®ç°
        """
        image = Image.open(image_path).convert('RGB')
        original_width, original_height = image.size
        
        # è°ƒæ•´å›¾åƒå¤§å°åˆ°640x640
        image_resized = image.resize((640, 640), Image.LANCZOS)
        img_array = np.array(image_resized).astype(np.float32) / 255.0
        img_tensor = jt.array(img_array.transpose(2, 0, 1)).float32().unsqueeze(0)
        
        return img_tensor, original_width, original_height, image
    
    def postprocess_predictions(self, outputs):
        """
        åå¤„ç†é¢„æµ‹ç»“æœ
        å‚è€ƒultimate_sanity_check.pyçš„å®ç°
        """
        if 'pred_logits' not in outputs or 'pred_boxes' not in outputs:
            return np.array([]), np.array([]), np.array([])
        
        pred_logits = outputs['pred_logits'][0]  # [num_queries, num_classes]
        pred_boxes = outputs['pred_boxes'][0]    # [num_queries, 4]
        
        # è½¬æ¢ä¸ºnumpyå¹¶è®¡ç®—ç½®ä¿¡åº¦
        pred_logits_np = pred_logits.numpy()
        pred_boxes_np = pred_boxes.numpy()
        
        # ä½¿ç”¨softmaxè®¡ç®—ç½®ä¿¡åº¦
        scores = softmax(pred_logits_np, axis=-1)
        max_scores = np.max(scores[:, :-1], axis=-1)  # æ’é™¤èƒŒæ™¯ç±»
        predicted_labels = np.argmax(scores[:, :-1], axis=-1)
        
        # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
        valid_mask = max_scores > self.conf_threshold
        
        final_boxes = pred_boxes_np[valid_mask]
        final_scores = max_scores[valid_mask]
        final_labels = predicted_labels[valid_mask]
        
        return final_boxes, final_scores, final_labels
    
    def inference_single_image(self, image_path):
        """
        å•å¼ å›¾åƒæ¨ç†
        
        Args:
            image_path: å›¾åƒè·¯å¾„
        
        Returns:
            results: æ£€æµ‹ç»“æœå­—å…¸
        """
        # é¢„å¤„ç†
        img_tensor, original_width, original_height, original_image = self.preprocess_image(image_path)
        
        # æ¨ç†
        self.model.eval()
        with jt.no_grad():
            outputs = self.model(img_tensor)
        
        # åå¤„ç†
        pred_boxes, pred_scores, pred_labels = self.postprocess_predictions(outputs)
        
        return {
            'image_path': image_path,
            'original_image': original_image,
            'original_width': original_width,
            'original_height': original_height,
            'pred_boxes': pred_boxes,
            'pred_scores': pred_scores,
            'pred_labels': pred_labels,
            'num_detections': len(pred_boxes)
        }
    
    def visualize_detection(self, results, save_path=None, show_confidence=True):
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ
        
        Args:
            results: æ¨ç†ç»“æœ
            save_path: ä¿å­˜è·¯å¾„
            show_confidence: æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦
        """
        image = results['original_image'].copy()
        draw = ImageDraw.Draw(image)
        
        # å°è¯•åŠ è½½å­—ä½“
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
        except:
            font = ImageFont.load_default()
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for i, (box, score, label) in enumerate(zip(results['pred_boxes'], results['pred_scores'], results['pred_labels'])):
            # è½¬æ¢åæ ‡åˆ°åŸå§‹å›¾åƒå°ºå¯¸
            x1, y1, x2, y2 = box
            x1 = x1 * results['original_width']
            y1 = y1 * results['original_height']
            x2 = x2 * results['original_width']
            y2 = y2 * results['original_height']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            draw.rectangle([x1, y1, x2, y2], outline='red', width=3)
            
            # ç»˜åˆ¶æ ‡ç­¾å’Œç½®ä¿¡åº¦
            label_id = int(label) + 1  # è½¬æ¢å›COCO ID
            class_name = COCO_CLASSES.get(label_id, f"class_{label_id}")
            
            if show_confidence:
                text = f"{class_name}: {score:.2f}"
            else:
                text = class_name
            
            # è®¡ç®—æ–‡æœ¬ä½ç½®
            text_bbox = draw.textbbox((0, 0), text, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]
            
            # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
            draw.rectangle([x1, y1-text_height-5, x1+text_width+10, y1], fill='red')
            
            # ç»˜åˆ¶æ–‡æœ¬
            draw.text((x1+5, y1-text_height-2), text, fill='white', font=font)
        
        # ä¿å­˜å›¾åƒ
        if save_path is None:
            filename = os.path.basename(results['image_path'])
            name, ext = os.path.splitext(filename)
            save_path = os.path.join(self.save_dir, f"{name}_detection{ext}")
        
        image.save(save_path)
        print(f"ğŸ“Š æ£€æµ‹ç»“æœä¿å­˜åˆ°: {save_path}")
        
        return save_path
    
    def create_detection_summary(self, results):
        """åˆ›å»ºæ£€æµ‹æ‘˜è¦"""
        summary = {
            'image_file': os.path.basename(results['image_path']),
            'image_size': f"{results['original_width']}x{results['original_height']}",
            'num_detections': results['num_detections'],
            'detections': []
        }
        
        for box, score, label in zip(results['pred_boxes'], results['pred_scores'], results['pred_labels']):
            label_id = int(label) + 1
            class_name = COCO_CLASSES.get(label_id, f"class_{label_id}")
            
            detection = {
                'class_name': class_name,
                'class_id': label_id,
                'confidence': float(score),
                'bbox': [float(x) for x in box]  # [x1, y1, x2, y2] normalized
            }
            summary['detections'].append(detection)
        
        return summary
    
    def batch_inference(self, image_paths, save_visualizations=True):
        """
        æ‰¹é‡æ¨ç†
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            save_visualizations: æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœ
        
        Returns:
            all_results: æ‰€æœ‰æ¨ç†ç»“æœ
        """
        all_results = []
        
        print(f"ğŸ” å¼€å§‹æ‰¹é‡æ¨ç† {len(image_paths)} å¼ å›¾åƒ...")
        
        for i, image_path in enumerate(image_paths):
            print(f"   å¤„ç†å›¾åƒ {i+1}/{len(image_paths)}: {os.path.basename(image_path)}")
            
            try:
                # æ¨ç†
                results = self.inference_single_image(image_path)
                all_results.append(results)
                
                print(f"     æ£€æµ‹åˆ° {results['num_detections']} ä¸ªç›®æ ‡")
                
                # ä¿å­˜å¯è§†åŒ–
                if save_visualizations:
                    self.visualize_detection(results)
                
            except Exception as e:
                print(f"     âŒ å¤„ç†å¤±è´¥: {e}")
                continue
        
        print(f"âœ… æ‰¹é‡æ¨ç†å®Œæˆ! æˆåŠŸå¤„ç† {len(all_results)} å¼ å›¾åƒ")
        return all_results
    
    def print_detection_stats(self, all_results):
        """æ‰“å°æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        if not all_results:
            print("âš ï¸ æ²¡æœ‰æ£€æµ‹ç»“æœ")
            return
        
        total_detections = sum(r['num_detections'] for r in all_results)
        avg_detections = total_detections / len(all_results)
        
        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        class_counts = {}
        confidence_scores = []
        
        for results in all_results:
            for label, score in zip(results['pred_labels'], results['pred_scores']):
                label_id = int(label) + 1
                class_name = COCO_CLASSES.get(label_id, f"class_{label_id}")
                class_counts[class_name] = class_counts.get(class_name, 0) + 1
                confidence_scores.append(score)
        
        print(f"\nğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
        print(f"   å¤„ç†å›¾åƒæ•°: {len(all_results)}")
        print(f"   æ€»æ£€æµ‹æ•°: {total_detections}")
        print(f"   å¹³å‡æ¯å¼ å›¾åƒæ£€æµ‹æ•°: {avg_detections:.1f}")
        
        if confidence_scores:
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence_scores):.3f}")
            print(f"   æœ€é«˜ç½®ä¿¡åº¦: {np.max(confidence_scores):.3f}")
            print(f"   æœ€ä½ç½®ä¿¡åº¦: {np.min(confidence_scores):.3f}")
        
        if class_counts:
            print(f"\nğŸ·ï¸ æ£€æµ‹ç±»åˆ«åˆ†å¸ƒ:")
            sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)
            for class_name, count in sorted_classes[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(f"   {class_name}: {count}")

def create_visualizer(model, conf_threshold=0.3, save_dir="./results/visualizations"):
    """
    åˆ›å»ºå¯è§†åŒ–å™¨çš„å·¥å‚å‡½æ•°
    
    Args:
        model: RT-DETRæ¨¡å‹
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        save_dir: ä¿å­˜ç›®å½•
    
    Returns:
        visualizer: RT-DETRå¯è§†åŒ–å™¨
    """
    visualizer = RTDETRVisualizer(model, conf_threshold, save_dir)
    return visualizer

if __name__ == "__main__":
    # æµ‹è¯•å¯è§†åŒ–ç»„ä»¶
    print("ğŸ§ª æµ‹è¯•RT-DETRå¯è§†åŒ–ç»„ä»¶")
    print("=" * 50)
    
    try:
        # è¿™é‡Œéœ€è¦å®é™…çš„æ¨¡å‹æ¥æµ‹è¯•
        # åœ¨å®é™…ä½¿ç”¨æ—¶ï¼Œæ¨¡å‹ä¼šä»modelç»„ä»¶å¯¼å…¥
        print("âš ï¸ å¯è§†åŒ–ç»„ä»¶éœ€è¦é…åˆè®­ç»ƒå¥½çš„æ¨¡å‹ä½¿ç”¨")
        print("   è¯·å‚è€ƒvis_script.pyä¸­çš„å®Œæ•´ä½¿ç”¨ç¤ºä¾‹")
        
        print(f"\nğŸ‰ RT-DETRå¯è§†åŒ–ç»„ä»¶éªŒè¯å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–ç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
